{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
    "                 max_depth: int = 5, min_samples_leaf: int = 8):\n",
    "        self._prepare_data()\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "        # допишите ваш код здесь\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        # допишите ваш код здесь \n",
    "        pass\n",
    "\n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        # допишите ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        # допишите ваш код здесь\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code to send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
    "                 max_depth: int = 5, min_samples_leaf: int = 8):\n",
    "        self._prepare_data()\n",
    "\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "        # допишите ваш код здесь\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        \n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[0].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[0].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        \n",
    "        # scale train data\n",
    "        self.X_train = torch.FloatTensor(self._scale_features_in_query_groups(\n",
    "            inp_feat_array=X_train, inp_query_ids=self.query_ids_train))\n",
    "#         self.ys_train = torch.FloatTensor(y_train).t()\n",
    "        self.ys_train = torch.FloatTensor(y_train).reshape(-1,1)\n",
    "        \n",
    "        # scale test data\n",
    "        self.X_test = torch.FloatTensor(self._scale_features_in_query_groups(\n",
    "            inp_feat_array=X_test, inp_query_ids=self.query_ids_test))\n",
    "#         self.ys_test = torch.FloatTensor(y_test).t()\n",
    "        self.ys_test = torch.FloatTensor(y_test).reshape(-1,1)\n",
    "        pass\n",
    "\n",
    "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "        # get unique ids\n",
    "        inp_query_ids_uniq = np.unique(inp_query_ids)\n",
    "        \n",
    "        # scale each group by id\n",
    "        for id_i in inp_query_ids_uniq:\n",
    "            scaler = StandardScaler()\n",
    "            inp_feat_array[inp_query_ids == id_i, :] = \\\n",
    "                scaler.fit_transform(inp_feat_array[inp_query_ids == id_i, :])\n",
    "\n",
    "        return inp_feat_array\n",
    "\n",
    "    \n",
    "    \n",
    "    def _train_one_tree(self, cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        # допишите ваш код здесь\n",
    "#         random.seed(cur_tree_idx)\n",
    "        \n",
    "        ## compute lambdas with train_preds\n",
    "        ids_uniq = np.unique(self.query_ids_train)\n",
    "        \n",
    "#         print('self.train_preds')\n",
    "#         print(self.train_preds)\n",
    "#         print('np.shape(self.train_preds)')\n",
    "#         print(np.shape(self.train_preds))\n",
    "#         if all(np.array(self.train_preds) == 0):\n",
    "#             lambdas_upd = self.ys_train\n",
    "#         else:\n",
    "        lambdas_list = []\n",
    "\n",
    "        for n_id in ids_uniq:\n",
    "\n",
    "            X_train_id = self.X_train[self.query_ids_train == n_id]\n",
    "            ys_train_id = self.ys_train[self.query_ids_train == n_id]\n",
    "            train_preds_id = train_preds[self.query_ids_train == n_id]\n",
    "\n",
    "            lambdas_list.append(\\\n",
    "                self._compute_lambdas(y_true=ys_train_id, y_pred=train_preds_id))\n",
    "\n",
    "#             lambdas_upd = np.concatenate(lambdas_list)\n",
    "        lambdas_upd = np.concatenate(lambdas_list) * -1\n",
    "#             lambdas_upd = np.concatenate(lambdas_list) * -1 * self.lr\n",
    "        \n",
    "        ## set train data\n",
    "        N, M = np.shape(self.X_train)\n",
    "        \n",
    "        random.seed(cur_tree_idx + 1)\n",
    "        sample_ids = random.sample(range(N), int(N * self.subsample))\n",
    "        random.seed(cur_tree_idx + 1)\n",
    "        colsample_ids = np.array(random.sample(range(M), int(M * self.colsample_bytree)))\n",
    "        \n",
    "#         print('np.shape(self.X_train)')\n",
    "#         print(np.shape(self.X_train))\n",
    "#         print('np.shape(sample_ids)')\n",
    "#         print(np.shape(sample_ids))\n",
    "#         print('np.shape(colsample_ids)')\n",
    "#         print(np.shape(colsample_ids))\n",
    "        X_train = self.X_train[sample_ids, :][:, colsample_ids]\n",
    "#         ys_train = self.ys_train[sample_ids, ]\n",
    "#         ys_train = train_preds[sample_ids]\n",
    "        ys_train = lambdas_upd[sample_ids]\n",
    "        \n",
    "#         print('ys_train_train_one_tree')\n",
    "#         print(ys_train)\n",
    "        \n",
    "        # fit one tree & predict\n",
    "        single_tree = DecisionTreeRegressor(max_depth=self.max_depth,\\\n",
    "                                            min_samples_leaf=self.min_samples_leaf,\\\n",
    "                                            random_state=cur_tree_idx + 1)\n",
    "        single_tree.fit(X=X_train, y=ys_train)\n",
    "        \n",
    "        # return tree and features ids\n",
    "        return (single_tree, colsample_ids)\n",
    "\n",
    "    \n",
    "#     def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "#         # допишите ваш код здесь\n",
    "#         pass\n",
    "    \n",
    "    def _compute_lambdas(self, y_true, y_pred, ndcg_scheme='exp2'):\n",
    "        # рассчитаем нормировку, IdealDCG\n",
    "#         print('y_true')\n",
    "#         print(y_true)\n",
    "#         print('y_pred')\n",
    "#         print(y_pred)\n",
    "        if all(np.array(y_true) == 0):\n",
    "            ideal_dcg = 1\n",
    "        else:\n",
    "            ideal_dcg = self._compute_ideal_dcg(y_true.reshape(1,-1)[0],\\\n",
    "                                            ndcg_scheme=ndcg_scheme)\n",
    "        \n",
    "#         print('ideal_dcg')\n",
    "#         print(ideal_dcg)\n",
    "        N = 1 / ideal_dcg\n",
    "\n",
    "        # рассчитаем порядок документов согласно оценкам релевантности\n",
    "        _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "        rank_order += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # получаем все попарные разницы скоров в батче\n",
    "#             pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "            pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.reshape(-1,1)))\n",
    "#             print('pos_pairs_score_diff')\n",
    "#             print(pos_pairs_score_diff)\n",
    "            \n",
    "            # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "            # -1 если второй документ релевантнее\n",
    "            Sij = self._compute_labels_in_batch(y_true)\n",
    "#             print('Sij')\n",
    "#             print(Sij)\n",
    "            # посчитаем изменение gain из-за перестановок\n",
    "            gain_diff = self._compute_gain_diff(y_true, ndcg_scheme)\n",
    "#             print('gain_diff')\n",
    "#             print(gain_diff)\n",
    "            \n",
    "            # посчитаем изменение знаменателей-дискаунтеров\n",
    "#             decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "            decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - \\\n",
    "                (1.0 / torch.log2(rank_order.reshape(1,-1) + 1.0))\n",
    "#             print('decay_diff')\n",
    "#             print(decay_diff)\n",
    "            # посчитаем непосредственное изменение nDCG\n",
    "            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "            # посчитаем лямбды\n",
    "            lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "#             print('lambda_update')\n",
    "#             print(lambda_update)\n",
    "            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "\n",
    "#             return Sij, gain_diff, decay_diff, delta_ndcg, lambda_update\n",
    "        return lambda_update\n",
    "    \n",
    "    def _compute_labels_in_batch(self, y_true):\n",
    "\n",
    "        # разница релевантностей каждого с каждым объектом\n",
    "#         print('y_true_in_compute_labels_in_batch')\n",
    "#         print(y_true)\n",
    "#         rel_diff = y_true - y_true.t()\n",
    "        rel_diff = y_true - y_true.reshape(1,-1)\n",
    "#         print('rel_diff')\n",
    "#         print(rel_diff)\n",
    "        \n",
    "        # 1 в этой матрице - объект более релевантен\n",
    "        pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "\n",
    "        # 1 тут - объект менее релевантен\n",
    "        neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "        Sij = pos_pairs - neg_pairs\n",
    "        return Sij\n",
    "\n",
    "    def _compute_gain_diff(self, y_true, gain_scheme):\n",
    "        if gain_scheme == \"exp2\":\n",
    "#             gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "            gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.reshape(1,-1))\n",
    "        elif gain_scheme == \"diff\":\n",
    "            gain_diff = y_true - y_true.t()\n",
    "        else:\n",
    "            raise ValueError(f\"{gain_scheme} method not supported\")\n",
    "        return gain_diff\n",
    "    \n",
    "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "        \n",
    "        ndcgs = []\n",
    "        \n",
    "        # допишите ваш код здесь\n",
    "        with torch.no_grad():\n",
    "\n",
    "#             ids_test_uniq = np.unique(self.query_ids_test)\n",
    "\n",
    "#             for id_test in ids_test_uniq:\n",
    "#                 cur_X_test = self.X_test[self.query_ids_test == id_test, :]\n",
    "#                 valid_pred = self.predict(cur_X_test)\n",
    "#                 cur_ndcg = self._ndcg_k(\\\n",
    "#                     ys_true=self.ys_test.reshape(1,-1)[0][self.query_ids_test == id_test],\\\n",
    "#                     ys_pred=valid_pred,\\\n",
    "#                     ndcg_top_k=10)\n",
    "                \n",
    "            ids_test_uniq = np.unique(queries_list)\n",
    "\n",
    "            for id_test in ids_test_uniq:\n",
    "                cur_ndcg = self._ndcg_k(\\\n",
    "                    ys_true=true_labels[queries_list == id_test],\\\n",
    "                    ys_pred=preds[queries_list == id_test],\\\n",
    "                    ndcg_top_k=self.ndcg_top_k)\n",
    "                \n",
    "                ndcgs.append(cur_ndcg)\n",
    "                \n",
    "        return np.mean(ndcgs)\n",
    "\n",
    "    def fit(self):\n",
    "        np.random.seed(0)\n",
    "        # допишите ваш код здесь\n",
    "        self.train_preds = torch.zeros(np.shape(self.ys_train)[0])\n",
    "        self.features_ids = []\n",
    "        self.trees = []\n",
    "        self.best_ndcg = 0\n",
    "        self.best_n_trees = 1\n",
    "        self.ndcg_list = []\n",
    "        \n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            single_tree, features_ids = self._train_one_tree(\\\n",
    "                cur_tree_idx=i, train_preds=self.train_preds)\n",
    "            self.trees.append(single_tree)\n",
    "            self.features_ids.append(features_ids)\n",
    "            \n",
    "            ## calculate new tree prediction & update train_preds\n",
    "            new_ys_preds = single_tree.predict(self.X_train[:, features_ids])\n",
    "#             self.train_preds += new_ys_preds\n",
    "            self.train_preds += new_ys_preds * self.lr\n",
    "            \n",
    "#             print('new_ys_preds')\n",
    "#             print(new_ys_preds)\n",
    "#             print('self.train_preds')\n",
    "#             print(self.train_preds)\n",
    "            \n",
    "            ## calc new ndcg and update best & best_n_tree with _calc_data_ndcg\n",
    "            \n",
    "            # apply _calc_data_ndcg\n",
    "            ndcg_cur_train = self._calc_data_ndcg(\\\n",
    "                queries_list=self.query_ids_train, true_labels=self.ys_train,\\\n",
    "                preds=self.predict(self.X_train))\n",
    "            \n",
    "            ndcg_cur_test = self._calc_data_ndcg(\\\n",
    "                queries_list=self.query_ids_test, true_labels=self.ys_test,\\\n",
    "                preds=self.predict(self.X_test))\n",
    "            \n",
    "            ndcg_cur = ndcg_cur_test\n",
    "            self.ndcg_list.append(ndcg_cur)\n",
    "            self.best_ndcg = max(self.ndcg_list)\n",
    "            self.best_n_trees = np.argmax(self.ndcg_list) + 1\n",
    "            \n",
    "# #             print('i_in_fit_fun')\n",
    "#             print(i)\n",
    "# #             print('ndcg_cur_in_fit_fun')\n",
    "#             print(ndcg_cur)\n",
    "            print(\"n_tree: {}, train_ndcg_k: {}, test_ndcg_k: {}\".format(\\\n",
    "                i, ndcg_cur_train, ndcg_cur_test))\n",
    "        \n",
    "        self.trees = self.trees[:self.best_n_trees]\n",
    "        self.features_ids = self.features_ids[:self.best_n_trees]\n",
    "        self.n_estimators = self.best_n_trees\n",
    "        \n",
    "#         self.trees = trees_list\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        # допишите ваш код здесь\n",
    "        preds = torch.zeros(np.shape(data)[0])\n",
    "#         for i in range(self.n_estimators):\n",
    "        for i in range(len(self.trees)):\n",
    "#             print('len(self.trees)')\n",
    "#             print(len(self.trees))\n",
    "            ## calculate new tree prediction & update train_preds\n",
    "#             print(\"n_estimator_i\")\n",
    "#             print(i)\n",
    "            new_ys_preds = self.trees[i].predict(data[:, self.features_ids[i]])\n",
    "#             self.train_preds += new_ys_preds * self.lr\n",
    "            preds += new_ys_preds * self.lr\n",
    "            \n",
    "        return preds\n",
    "            \n",
    "#     def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n",
    "#         # допишите ваш код здесь\n",
    "#         pass\n",
    "    \n",
    "    def _ndcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n",
    "                ndcg_top_k: int) -> float:\n",
    "        # допишите ваш код здесь\n",
    "        ys_true = torch.reshape(ys_true, (-1,))\n",
    "        ys_pred = torch.reshape(ys_pred, (-1,))\n",
    "\n",
    "        ys_pred_sorted = torch.sort(ys_pred, descending=True)\n",
    "        ys_true_sorted = ys_true[ys_pred_sorted[1]]\n",
    "        ys_true_sorted_sep = torch.sort(ys_true, descending=True)[0]\n",
    "\n",
    "        dcg_act = self._dcg(ys_true=ys_true_sorted[:self.ndcg_top_k],\\\n",
    "                            ys_pred=ys_pred_sorted[0][:self.ndcg_top_k],\\\n",
    "                            gain_scheme='exp2')\n",
    "\n",
    "        dcg_max = self._dcg(ys_true=ys_true_sorted_sep[:self.ndcg_top_k],\\\n",
    "                            ys_pred=ys_true_sorted_sep[:self.ndcg_top_k],\\\n",
    "                            gain_scheme='exp2')\n",
    "\n",
    "#         try:\n",
    "#             ndcg_k = dcg_act / dcg_max\n",
    "#         except:\n",
    "#             ndcg_k = 0\n",
    "#         if np.isnan(ndcg_k):\n",
    "#             ndcg_k = 0\n",
    "        \n",
    "#         if (dcg_act == 0):\n",
    "#             ndcg_k = 0\n",
    "        if (dcg_max == 0):\n",
    "            ndcg_k = 1\n",
    "        else:\n",
    "            ndcg_k = dcg_act / dcg_max\n",
    "        \n",
    "        return ndcg_k\n",
    "\n",
    "    def _ndcg(self, ys_true: torch.Tensor, ys_pred: torch.Tensor, gain_scheme: str = 'const') -> float:\n",
    "#         try:\n",
    "        dcg_val = self._dcg(ys_true=ys_true, ys_pred=ys_pred, gain_scheme=gain_scheme)\n",
    "        ideal_dcg_val = self._dcg(ys_true=ys_true, ys_pred=ys_true, gain_scheme=gain_scheme)\n",
    "        \n",
    "#         print('dcg_val')\n",
    "#         print(dcg_val)\n",
    "#         print('ideal_dcg_val')\n",
    "#         print(ideal_dcg_val)\n",
    "        \n",
    "#         if (dcg_val == 0):\n",
    "#             return dcg_val\n",
    "        if (ideal_dcg_val == 0):\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return dcg_val / ideal_dcg_val\n",
    "    \n",
    "    def _compute_gain(self, y_value: float, gain_scheme: str) -> float:\n",
    "#         return 2 ** y_value - 1.\n",
    "        if gain_scheme == 'exp2':\n",
    "            return 2 ** y_value - 1.\n",
    "        else:\n",
    "            return y_value + 0.\n",
    "\n",
    "    def _dcg(self, ys_true: torch.Tensor, ys_pred: torch.Tensor, gain_scheme: str) -> float:\n",
    "        ys_pred_sorted = torch.sort(ys_pred, descending=True)\n",
    "#         print('ys_pred_sorted')\n",
    "#         print(ys_pred_sorted)\n",
    "        \n",
    "        log2_list = [math.log2(x) for x in range(2, len(ys_pred) + 2)]\n",
    "\n",
    "        dcg_val = 0.\n",
    "        for i in range(len(log2_list)):\n",
    "            dcg_val += self._compute_gain(ys_true[ys_pred_sorted[1]][i].item(), \\\n",
    "                                          gain_scheme=gain_scheme) / log2_list[i]\n",
    "            \n",
    "#         print('dcg_val')\n",
    "#         print(dcg_val)\n",
    "        \n",
    "#         if (dcg_val == 0):\n",
    "# #             dcg_val = -1\n",
    "#             dcg_val = 0.00001\n",
    "        return dcg_val\n",
    "    \n",
    "    def _compute_ideal_dcg(self, y_true, ndcg_scheme='exp2'):\n",
    "#         print(y_true)\n",
    "#         try:\n",
    "        return self._dcg(ys_true=y_true, ys_pred=y_true, gain_scheme=ndcg_scheme)\n",
    "#         except:\n",
    "#             return 1\n",
    "    \n",
    "    \n",
    "    def save_model(self, path: str):\n",
    "        # допишите ваш код здесь\n",
    "        ## save model\n",
    "        state = {\n",
    "            'trees': self.trees, \n",
    "            'features_ids': self.features_ids,\n",
    "            'ndcg_top_k': self.ndcg_top_k,\n",
    "#             'best_n_trees': self.best_n_trees,\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'lr': self.lr}\n",
    "        \n",
    "        f = open(path, 'wb')\n",
    "        pickle.dump(state, f)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        # допишите ваш код здесь\n",
    "        f = open(path, 'rb')\n",
    "        state = pickle.load(f)\n",
    "        \n",
    "        self.trees = state['trees']\n",
    "        self.features_ids = state['features_ids']\n",
    "        self.ndcg_top_k = state['ndcg_top_k']\n",
    "#         self.best_n_trees = state['best_n_trees']\n",
    "        self.lr = state['lr']\n",
    "        \n",
    "#         return state\n",
    "        pass\n",
    "    \n",
    "#     def save_obj(obj, name):\n",
    "#         with open(name + '.pkl', 'wb') as f:\n",
    "#             pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#     def load_obj(name):\n",
    "#         with open(name + '.pkl', 'rb') as f:\n",
    "#             return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
    "#                  subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
    "#                  max_depth: int = 5, min_samples_leaf: int = 8)\n",
    "\n",
    "# tst_sol1 = Solution(n_estimators=100, lr=0.2)\n",
    "# tst_sol1 = Solution(n_estimators=7)\n",
    "tst_sol1 = Solution(n_estimators=70, lr=0.3, min_samples_leaf=5, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tree: 0, train_ndcg_k: 0.3974207986909805, test_ndcg_k: 0.3017928567355241\n",
      "n_tree: 1, train_ndcg_k: 0.4500903917906584, test_ndcg_k: 0.3432646399673279\n",
      "n_tree: 2, train_ndcg_k: 0.4730508459962984, test_ndcg_k: 0.363925927797515\n",
      "n_tree: 3, train_ndcg_k: 0.49682397442435555, test_ndcg_k: 0.39265733643346307\n",
      "n_tree: 4, train_ndcg_k: 0.4953915464952521, test_ndcg_k: 0.3964837303533704\n",
      "n_tree: 5, train_ndcg_k: 0.4980256981430127, test_ndcg_k: 0.3921231947896045\n",
      "n_tree: 6, train_ndcg_k: 0.501016161757284, test_ndcg_k: 0.39985701992250083\n",
      "n_tree: 7, train_ndcg_k: 0.503211403133101, test_ndcg_k: 0.39782477229975066\n",
      "n_tree: 8, train_ndcg_k: 0.49742028680168887, test_ndcg_k: 0.3991079400442628\n",
      "n_tree: 9, train_ndcg_k: 0.500173568571824, test_ndcg_k: 0.40124577189886135\n",
      "n_tree: 10, train_ndcg_k: 0.4981307024483223, test_ndcg_k: 0.4022730857592981\n",
      "n_tree: 11, train_ndcg_k: 0.50258946281091, test_ndcg_k: 0.39235613482732196\n",
      "n_tree: 12, train_ndcg_k: 0.5031757634892372, test_ndcg_k: 0.3979112728885248\n",
      "n_tree: 13, train_ndcg_k: 0.5102916633102335, test_ndcg_k: 0.3950285715434678\n",
      "n_tree: 14, train_ndcg_k: 0.5067510068529427, test_ndcg_k: 0.3950609985670319\n",
      "n_tree: 15, train_ndcg_k: 0.505114099166144, test_ndcg_k: 0.40060020249980755\n",
      "n_tree: 16, train_ndcg_k: 0.5038352980715785, test_ndcg_k: 0.4078480295698277\n",
      "n_tree: 17, train_ndcg_k: 0.5024824190913005, test_ndcg_k: 0.4048126257906901\n",
      "n_tree: 18, train_ndcg_k: 0.5040910988170917, test_ndcg_k: 0.3959313871823975\n",
      "n_tree: 19, train_ndcg_k: 0.5018313155772236, test_ndcg_k: 0.39716237616061717\n",
      "n_tree: 20, train_ndcg_k: 0.4958344003963279, test_ndcg_k: 0.39351157552088056\n",
      "n_tree: 21, train_ndcg_k: 0.49361988881044494, test_ndcg_k: 0.3922784108754231\n",
      "n_tree: 22, train_ndcg_k: 0.49491796260683296, test_ndcg_k: 0.3923852739454885\n",
      "n_tree: 23, train_ndcg_k: 0.4947212006977508, test_ndcg_k: 0.3914512058604109\n",
      "n_tree: 24, train_ndcg_k: 0.49648361840175026, test_ndcg_k: 0.3945725197366452\n",
      "n_tree: 25, train_ndcg_k: 0.49510114778130054, test_ndcg_k: 0.39463844125615305\n",
      "n_tree: 26, train_ndcg_k: 0.4953792465158482, test_ndcg_k: 0.39479986959599456\n",
      "n_tree: 27, train_ndcg_k: 0.4986430188785228, test_ndcg_k: 0.391258180733552\n",
      "n_tree: 28, train_ndcg_k: 0.4996327318695247, test_ndcg_k: 0.3916685082592279\n",
      "n_tree: 29, train_ndcg_k: 0.5026532460714249, test_ndcg_k: 0.39178921808943323\n",
      "n_tree: 30, train_ndcg_k: 0.5035830105449296, test_ndcg_k: 0.39255545069247444\n",
      "n_tree: 31, train_ndcg_k: 0.5084229244665012, test_ndcg_k: 0.3934634453238112\n",
      "n_tree: 32, train_ndcg_k: 0.5039285883173711, test_ndcg_k: 0.3933452854180466\n",
      "n_tree: 33, train_ndcg_k: 0.5054776482546218, test_ndcg_k: 0.3986934521005124\n",
      "n_tree: 34, train_ndcg_k: 0.5036625347542247, test_ndcg_k: 0.39774184547092534\n",
      "n_tree: 35, train_ndcg_k: 0.5026947228749289, test_ndcg_k: 0.3947290204859543\n",
      "n_tree: 36, train_ndcg_k: 0.503029259430278, test_ndcg_k: 0.3931710785969585\n",
      "n_tree: 37, train_ndcg_k: 0.5031888255514442, test_ndcg_k: 0.39293913818552667\n",
      "n_tree: 38, train_ndcg_k: 0.5014264927381261, test_ndcg_k: 0.39589009686870225\n",
      "n_tree: 39, train_ndcg_k: 0.49736325553713323, test_ndcg_k: 0.39625277190313035\n",
      "n_tree: 40, train_ndcg_k: 0.5035627675560951, test_ndcg_k: 0.39635213305286643\n",
      "n_tree: 41, train_ndcg_k: 0.4989098488927704, test_ndcg_k: 0.3967900595075577\n",
      "n_tree: 42, train_ndcg_k: 0.49774311808611804, test_ndcg_k: 0.3931108276307629\n",
      "n_tree: 43, train_ndcg_k: 0.49831183269279616, test_ndcg_k: 0.3926988157795966\n",
      "n_tree: 44, train_ndcg_k: 0.49952235303515397, test_ndcg_k: 0.3931584254598333\n",
      "n_tree: 45, train_ndcg_k: 0.49706812945132844, test_ndcg_k: 0.3922628996343102\n",
      "n_tree: 46, train_ndcg_k: 0.49616237066894914, test_ndcg_k: 0.39295947300986445\n",
      "n_tree: 47, train_ndcg_k: 0.4995686740950932, test_ndcg_k: 0.38931230968713526\n",
      "n_tree: 48, train_ndcg_k: 0.4987590703318039, test_ndcg_k: 0.38851542631148206\n",
      "n_tree: 49, train_ndcg_k: 0.4996207535152008, test_ndcg_k: 0.38927113996110146\n",
      "n_tree: 50, train_ndcg_k: 0.49983216668325836, test_ndcg_k: 0.39120776886434283\n",
      "n_tree: 51, train_ndcg_k: 0.4996753630169699, test_ndcg_k: 0.3939250931989628\n",
      "n_tree: 52, train_ndcg_k: 0.4989752146768199, test_ndcg_k: 0.39456285207618086\n",
      "n_tree: 53, train_ndcg_k: 0.49765963721265394, test_ndcg_k: 0.3943494093368068\n",
      "n_tree: 54, train_ndcg_k: 0.49852803778262783, test_ndcg_k: 0.3950550615180901\n",
      "n_tree: 55, train_ndcg_k: 0.5011102430066465, test_ndcg_k: 0.39011923905152324\n",
      "n_tree: 56, train_ndcg_k: 0.5066079410379042, test_ndcg_k: 0.3884797682430248\n",
      "n_tree: 57, train_ndcg_k: 0.5069097861765016, test_ndcg_k: 0.38750213770781344\n",
      "n_tree: 58, train_ndcg_k: 0.5061264451188232, test_ndcg_k: 0.3866808230407916\n",
      "n_tree: 59, train_ndcg_k: 0.5058902984775014, test_ndcg_k: 0.3879842134300537\n",
      "n_tree: 60, train_ndcg_k: 0.5037126260621211, test_ndcg_k: 0.38868398819953565\n",
      "n_tree: 61, train_ndcg_k: 0.5033985124982222, test_ndcg_k: 0.3898032188299425\n",
      "n_tree: 62, train_ndcg_k: 0.5085576854117666, test_ndcg_k: 0.3935733916313351\n",
      "n_tree: 63, train_ndcg_k: 0.5075256151572234, test_ndcg_k: 0.39333251458325447\n",
      "n_tree: 64, train_ndcg_k: 0.5051277798795842, test_ndcg_k: 0.39535882224333024\n",
      "n_tree: 65, train_ndcg_k: 0.5065593707296641, test_ndcg_k: 0.3943467526922833\n",
      "n_tree: 66, train_ndcg_k: 0.5097515124006992, test_ndcg_k: 0.39587721472070925\n",
      "n_tree: 67, train_ndcg_k: 0.5087137649456143, test_ndcg_k: 0.3950408243284366\n",
      "n_tree: 68, train_ndcg_k: 0.5086595131693532, test_ndcg_k: 0.3967908734226\n",
      "n_tree: 69, train_ndcg_k: 0.5076696736395168, test_ndcg_k: 0.39623854910918016\n",
      "CPU times: user 5min 13s, sys: 2.29 s, total: 5min 16s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst_sol1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 0.4078480295698277)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_sol1.best_n_trees, tst_sol1.best_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tree: 0, train_ndcg_k: 0.45968059872384603, test_ndcg_k: 0.3295782293708683\n",
      "n_tree: 1, train_ndcg_k: 0.5216392964861525, test_ndcg_k: 0.336569784676915\n",
      "n_tree: 2, train_ndcg_k: 0.5221855200242471, test_ndcg_k: 0.36380267274701583\n",
      "n_tree: 3, train_ndcg_k: 0.5368954236716924, test_ndcg_k: 0.37187789290166084\n",
      "n_tree: 4, train_ndcg_k: 0.5403321922419148, test_ndcg_k: 0.3704574068159138\n",
      "n_tree: 5, train_ndcg_k: 0.5453128913862544, test_ndcg_k: 0.3725899192169184\n",
      "n_tree: 6, train_ndcg_k: 0.5485454855826337, test_ndcg_k: 0.3870515435122703\n",
      "CPU times: user 6.8 s, sys: 45.3 ms, total: 6.84 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# tst_sol1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_sol1.save_model(path='lambdamart_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_sol1.load_model(path='lambdamart_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_sol1.save_model(path='lambdamart_02.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 0.4321047855828739)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funs tests (draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(np.shape(tst_sol1.X_train)[0] * 0.9)\n",
    "N = np.shape(tst_sol1.X_train)[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[778, 127, 18, 845, 27, 423, 744, 182, 766, 725]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random()\n",
    "random.randint(0, 10)\n",
    "smpl1 = random.sample(range(1000), 10)\n",
    "smpl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3524, -0.4220,  0.4964,  ..., -0.1267, -0.0789, -0.4441],\n",
       "        [ 0.6456,  0.4900,  0.6141,  ...,  0.0000, -0.0974,  1.0093],\n",
       "        [ 0.3161, -0.2350, -0.3139,  ..., -0.1118, -0.1959, -0.2662],\n",
       "        ...,\n",
       "        [ 0.6456,  1.5499,  2.2621,  ...,  0.0000, -0.0977, -0.4654],\n",
       "        [ 0.3524, -0.4220,  0.4964,  ..., -0.1267, -0.0789, -0.4441],\n",
       "        [ 0.3524, -0.4220,  0.4964,  ..., -0.1267, -0.0789, -0.4441]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_sol1.X_train[smpl1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 55, 52, 57, 46, 97, 73, 39, 77,  6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = np.shape(tst_sol1.X_train[smpl1, ])\n",
    "np.array(random.sample(range(m), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[140260008804688,               0,               0],\n",
       "        [              0,               0,               0]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray([1,2,3], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6df22269584a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.ndarray([1,2,3], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', [1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('a', [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(tst_sol1.train_preds == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(range(2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 136])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tst_sol1.X_train[random.sample(range(5000), 1000), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [1000], [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-00cde338e3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtst_sol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# random.sample(range(100), 80)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [1000], [2]"
     ]
    }
   ],
   "source": [
    "tst_sol1.X_train[random.sample(range(5000), 1000), random.sample(range(10), 2)]\n",
    "# random.sample(range(100), 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ad07ebab6b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_sol1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "np.shape(tst_sol1.X_train[random.sample(range(5000), 1000), random.sample(range(10), 2)[:, np.newaxis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2744,  1.2814,  1.2673,  0.4213,  0.7169],\n",
       "        [ 1.2463, -1.1928,  1.2915,  1.2466,  0.1801],\n",
       "        [ 1.9949, -0.0971,  0.2938, -2.0156,  1.6405],\n",
       "        [ 0.0980, -2.7853, -0.0406, -0.0128,  0.6291]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 5)\n",
    "x\n",
    "# torch.index_select(x, 1, (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2814,  0.4213],\n",
       "        [-1.1928,  1.2466],\n",
       "        [-0.0971, -2.0156],\n",
       "        [-2.7853, -0.0128]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2814, -2.0156])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[0, 2], [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2814,  0.4213],\n",
       "        [-0.0971, -2.0156]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, [1, 3]][[0, 2], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2814,  0.4213],\n",
       "        [-0.0971, -2.0156]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, [1, 3]][[0, 2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2814,  0.4213],\n",
       "        [-0.0971, -2.0156]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[0, 2], :][:, [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]), array([1, 2, 3])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "z.append(np.array([1,2,3]))\n",
    "z.append(np.array([1,2,3]))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 0., 2., 1., 1., 1., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "        0., 0., 2., 2., 0., 1., 0., 1., 2., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 2., 3., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 2., 1., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t = torch.tensor([2., 2., 0., 2., 1., 1., 1., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\\\n",
    "        0., 0., 2., 2., 0., 1., 0., 1., 2., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\\\n",
    "        0., 0., 0., 0., 0., 1., 0., 0., 0., 2., 3., 0., 0., 0., 0., 0., 1., 0.,\\\n",
    "        0., 0., 2., 1., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\\\n",
    "        0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
    "tst_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 0., 2., 1., 1., 1., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "        0., 0., 2., 2., 0., 1., 0., 1., 2., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 2., 3., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 2., 1., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [5.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tst_t2 = torch.LongTensor([[5, 3, 2, 5, 1, 1]]).reshape(-1, 1)\n",
    "tst_t2 = torch.Tensor([[5, 3, 2, 5, 1, 1]]).reshape(-1, 1)\n",
    "tst_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3., 2., 5., 1., 1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t3 = torch.Tensor([5, 3, 2, 5, 1, 1])\n",
    "tst_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -2., -3.,  0., -4., -4.],\n",
       "        [ 2.,  0., -1.,  2., -2., -2.],\n",
       "        [ 3.,  1.,  0.,  3., -1., -1.],\n",
       "        [ 0., -2., -3.,  0., -4., -4.],\n",
       "        [ 4.,  2.,  1.,  4.,  0.,  0.],\n",
       "        [ 4.,  2.,  1.,  4.,  0.,  0.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t3 - tst_t3.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t3 - tst_t3.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(np.shape(tst_sol1.ys_train.reshape(1,-1)))\n",
    "torch.zeros(np.shape(tst_sol1.ys_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10000])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(torch.zeros(np.shape(tst_sol1.ys_train.reshape(1,-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [5.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t2 = torch.Tensor([[5, 3, 2, 5, 1, 1]]).reshape(-1, 1)\n",
    "tst_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3., 2., 5., 1., 1.])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_t2.reshape(1,-1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.]]).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([1,2,3,4,3,2,1])\n",
    "np.argmax([1,2,3,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([1,2,3,4,3,4,4,4,4,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,3,4,4,4,4,2,1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 7, 5, 3, 6, 9, 4, 8, 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "sample_ids = random.sample(range(10), int(5 * 2))\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 0, 6, 3, 4, 8, 1, 7, 2, 5]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(10)\n",
    "sample_ids = random.sample(range(10), int(5 * 2))\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
